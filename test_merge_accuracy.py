#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®Œæ•´çš„å­—å¹•åˆå¹¶å‡†ç¡®åº¦æµ‹è¯•
æµ‹è¯•å¤šä¸ªåŸå§‹SRTæ–‡ä»¶ä¸æœŸæœ›ç»“æœçš„å¯¹æ¯”
"""

import re
import random
from typing import List, Dict, Tuple
from pathlib import Path
from difflib import SequenceMatcher


def parse_srt_file(srt_path: str) -> List[Dict]:
    """è§£æ SRT æ–‡ä»¶"""
    segments = []

    with open(srt_path, 'r', encoding='utf-8') as f:
        content = f.read()

    pattern = r'(\d+)\n(\d{2}:\d{2}:\d{2},\d{3}) --> (\d{2}:\d{2}:\d{2},\d{3})\n(.*?)(?:\n\n|\Z)'
    matches = re.findall(pattern, content, re.DOTALL)

    for match in matches:
        index, start_str, end_str, text = match
        start_time = parse_timestamp(start_str)
        end_time = parse_timestamp(end_str)

        segments.append({
            'index': int(index),
            'start_time': start_time,
            'end_time': end_time,
            'text': text.strip()
        })

    return segments


def parse_timestamp(time_str: str) -> float:
    """å°† SRT æ—¶é—´æˆ³è½¬æ¢ä¸ºç§’æ•°"""
    time_str = time_str.replace(',', '.')
    parts = time_str.split(':')
    hours = int(parts[0])
    minutes = int(parts[1])
    seconds = float(parts[2])
    return hours * 3600 + minutes * 60 + seconds


def srt_segments_to_ocr_results(segments: List[Dict], fps: int = 30) -> Dict[str, Dict]:
    """å°† SRT æ®µè½è½¬æ¢ä¸ºæ¨¡æ‹Ÿçš„ OCR ç»“æœæ ¼å¼"""
    ocr_results = {}

    for seg in segments:
        start_time = seg['start_time']
        end_time = seg['end_time']
        text = seg['text']

        start_frame = int(start_time * fps)

        # æ¨¡æ‹Ÿä¸åŒçš„ç½®ä¿¡åº¦
        base_confidence = 0.95
        if 'æ²’' in text or 'è½' in text:
            base_confidence = 0.88
        elif 'æ²¡' in text or 'å‘¢' in text:
            base_confidence = 0.96

        confidence = base_confidence + random.uniform(-0.02, 0.02)
        confidence = max(0.0, min(1.0, confidence))

        frame_path = f"output/frames/frame_{start_frame:06d}.jpg"

        ocr_results[frame_path] = {
            'text': text,
            'box': [100, 50, 500, 100],
            'frame_index': start_frame,
            'items': [{
                'text': text,
                'simplified_text': text,
                'score': confidence,
                'box': [100, 50, 500, 100]
            }],
            'raw_result': [{
                'dt_polys': [[[100, 50], [500, 50], [500, 100], [100, 100]]],
                'rec_texts': [text],
                'rec_scores': [confidence],
                'rec_boxes': [[100, 50, 500, 100]]
            }]
        }

    return ocr_results


def compare_segments(merged: List[Dict], expected: List[Dict]) -> Dict:
    """å¯¹æ¯”åˆå¹¶ç»“æœä¸æœŸæœ›ç»“æœ"""
    stats = {
        'merged_count': len(merged),
        'expected_count': len(expected),
        'exact_matches': 0,
        'partial_matches': 0,
        'mismatches': [],
        'missing': [],
        'extra': []
    }

    matched_expected_indices = set()

    for i, merged_seg in enumerate(merged):
        best_match_idx = -1
        best_similarity = 0

        for j, expected_seg in enumerate(expected):
            if j in matched_expected_indices:
                continue

            # æ–‡æœ¬ç›¸ä¼¼åº¦
            text_sim = SequenceMatcher(None, merged_seg['text'], expected_seg['text']).ratio()

            # æ—¶é—´é‡å åº¦
            merged_start = merged_seg['start_time']
            merged_end = merged_seg['end_time']
            expected_start = expected_seg['start_time']
            expected_end = expected_seg['end_time']

            overlap_start = max(merged_start, expected_start)
            overlap_end = min(merged_end, expected_end)
            overlap = max(0, overlap_end - overlap_start)

            merged_duration = merged_end - merged_start
            expected_duration = expected_end - expected_start

            if merged_duration > 0 and expected_duration > 0:
                time_sim = overlap / max(merged_duration, expected_duration)
            else:
                time_sim = 0

            # ç»¼åˆç›¸ä¼¼åº¦
            total_sim = text_sim * 0.7 + time_sim * 0.3

            if total_sim > best_similarity:
                best_similarity = total_sim
                best_match_idx = j

        if best_similarity > 0.6:
            expected_seg = expected[best_match_idx]
            matched_expected_indices.add(best_match_idx)

            # æ£€æŸ¥æ˜¯å¦å®Œå…¨åŒ¹é…
            if merged_seg['text'] == expected_seg['text']:
                stats['exact_matches'] += 1
            else:
                stats['partial_matches'] += 1
                stats['mismatches'].append({
                    'merged': merged_seg,
                    'expected': expected_seg,
                    'similarity': best_similarity
                })
        else:
            stats['extra'].append(merged_seg)

    # æŸ¥æ‰¾ç¼ºå¤±çš„æ®µè½
    for j, expected_seg in enumerate(expected):
        if j not in matched_expected_indices:
            stats['missing'].append(expected_seg)

    return stats


def format_time(seconds: float) -> str:
    """æ ¼å¼åŒ–æ—¶é—´"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millis = int((seconds % 1) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"


def test_single_file(raw_srt: str, expected_srt: str, fps: int = 30) -> Dict:
    """æµ‹è¯•å•ä¸ªæ–‡ä»¶å¯¹"""
    from main import smart_chinese_similarity

    print(f"\n{'='*80}")
    print(f"æµ‹è¯•æ–‡ä»¶å¯¹:")
    print(f"  åŸå§‹æ–‡ä»¶: {raw_srt}")
    print(f"  æœŸæœ›ç»“æœ: {expected_srt}")
    print(f"{'='*80}\n")

    # 1. è¯»å–åŸå§‹ SRT
    print(f"[1/5] è¯»å–åŸå§‹ SRT æ–‡ä»¶")
    raw_segments = parse_srt_file(raw_srt)
    print(f"  âœ“ åŸå§‹æ®µè½æ•°: {len(raw_segments)}\n")

    # 2. è¯»å–æœŸæœ›ç»“æœ
    print(f"[2/5] è¯»å–æœŸæœ›ç»“æœ")
    expected_segments = parse_srt_file(expected_srt)
    print(f"  âœ“ æœŸæœ›æ®µè½æ•°: {len(expected_segments)}\n")

    # 3. è½¬æ¢ä¸ºæ¨¡æ‹Ÿ OCR ç»“æœ
    print(f"[3/5] è½¬æ¢ä¸ºæ¨¡æ‹Ÿ OCR ç»“æœ")
    ocr_results = srt_segments_to_ocr_results(raw_segments, fps)
    print(f"  âœ“ ç”Ÿæˆ OCR ç»“æœ: {len(ocr_results)} ä¸ªå¸§\n")

    # 4. åˆ›å»ºæµ‹è¯•æå–å™¨
    print(f"[4/5] æ‰§è¡Œæ™ºèƒ½åˆå¹¶")

    class TestExtractor:
        def __init__(self, fps, start_time):
            self.extract_fps = fps
            self.start_time = start_time
            try:
                from opencc import OpenCC
                self.cc = OpenCC('t2s')
            except ImportError:
                self.cc = None

        def _convert_to_simplified(self, text):
            if self.cc and text:
                return self.cc.convert(text)
            return text

        def _check_detection_regions_validity(self, dt_polys, frame_path):
            return True

        def _select_best_text_from_variants(self, text_variants):
            if not text_variants:
                return ""

            if isinstance(text_variants[0], str):
                text_variants = [{'text': t, 'confidence': 0.95} for t in text_variants]

            if len(text_variants) == 1:
                return text_variants[0]['text']

            sorted_variants = sorted(text_variants, key=lambda x: (x.get('confidence', 0.0), len(x['text'])), reverse=True)
            return sorted_variants[0]['text']

        def _fill_segment_gaps(self, merged_segments, filtered_frames, gap_time_threshold):
            final_segments = []
            frame_map = {f['frame_index']: f for f in filtered_frames}
            gap_filled_count = 0

            for seg_idx, segment in enumerate(merged_segments):
                start_frame = segment['start_frame']
                end_frame = segment['end_frame']
                text = segment['text']

                extended_end_frame = end_frame
                next_frame_idx = end_frame + 1

                while True:
                    if seg_idx < len(merged_segments) - 1:
                        next_segment_start = merged_segments[seg_idx + 1]['start_frame']
                        if next_frame_idx >= next_segment_start:
                            break

                    if next_frame_idx not in frame_map:
                        break

                    frame_data = frame_map[next_frame_idx]

                    if (frame_data['has_detection'] and
                        not frame_data['has_text'] and
                        frame_data['is_valid_region']):

                        prev_end_time = (extended_end_frame + 1) / self.extract_fps + self.start_time
                        curr_start_time = next_frame_idx / self.extract_fps + self.start_time
                        time_gap = curr_start_time - prev_end_time

                        if abs(time_gap) < 0.001:
                            extended_end_frame = next_frame_idx
                            gap_filled_count += 1
                            next_frame_idx += 1
                        else:
                            break
                    else:
                        break

                start_time = start_frame / self.extract_fps + self.start_time
                end_time = (extended_end_frame + 1) / self.extract_fps + self.start_time

                final_segments.append({
                    'text': text,
                    'start_time': start_time,
                    'end_time': end_time,
                    'start_frame': start_frame,
                    'end_frame': extended_end_frame
                })

            return final_segments

    test_extractor = TestExtractor(fps=fps, start_time=0)

    # æ‰§è¡Œåˆå¹¶
    def merge_segments_test(ocr_results, similarity_threshold=0.8, gap_time_threshold=2.0):
        if not ocr_results:
            return []

        sorted_results = sorted(ocr_results.items(), key=lambda x: x[1]['frame_index'])

        # æ­¥éª¤1ï¼šé¢„å¤„ç†
        filtered_frames = []

        for frame_path, value in sorted_results:
            frame_idx = value['frame_index']
            text = value['text'].strip() if 'text' in value else ""

            is_valid_region = True
            simplified_text = test_extractor._convert_to_simplified(text) if text else ""

            confidence = 0.95
            if 'items' in value and value['items']:
                scores = [item.get('score', 0.95) for item in value['items']]
                if scores:
                    confidence = sum(scores) / len(scores)

            filtered_frames.append({
                'frame_index': frame_idx,
                'frame_path': frame_path,
                'text': simplified_text if is_valid_region else "",
                'has_text': bool(simplified_text and is_valid_region),
                'has_detection': 'raw_result' in value and value['raw_result'] is not None,
                'is_valid_region': is_valid_region,
                'raw_result': value.get('raw_result'),
                'confidence': confidence
            })

        text_frames_count = sum(1 for f in filtered_frames if f['has_text'])

        if text_frames_count == 0:
            return []

        # æ­¥éª¤2ï¼šæ™ºèƒ½ç›¸ä¼¼åº¦åˆå¹¶
        merged_segments = []
        current_segment = None
        text_variants = []

        for frame_data in filtered_frames:
            if not frame_data['has_text']:
                continue

            frame_idx = frame_data['frame_index']
            text = frame_data['text']
            confidence = frame_data.get('confidence', 0.95)

            if current_segment is None:
                current_segment = {
                    'start_frame': frame_idx,
                    'end_frame': frame_idx,
                    'text': text,
                    'frame_indices': [frame_idx]
                }
                text_variants = [{'text': text, 'confidence': confidence}]
            else:
                current_end_time = (current_segment['end_frame'] + 1) / fps
                new_start_time = frame_idx / fps
                time_gap = new_start_time - current_end_time

                similarity = smart_chinese_similarity(current_segment['text'], text)

                is_time_continuous = abs(time_gap) < 0.001
                is_short_gap = 0 < time_gap < 0.15
                is_similar = similarity >= similarity_threshold

                should_merge = is_similar and (is_time_continuous or is_short_gap)

                if should_merge:
                    current_segment['end_frame'] = frame_idx
                    current_segment['frame_indices'].append(frame_idx)
                    text_variants.append({'text': text, 'confidence': confidence})
                else:
                    current_segment['text'] = test_extractor._select_best_text_from_variants(text_variants)
                    merged_segments.append(current_segment)

                    current_segment = {
                        'start_frame': frame_idx,
                        'end_frame': frame_idx,
                        'text': text,
                        'frame_indices': [frame_idx]
                    }
                    text_variants = [{'text': text, 'confidence': confidence}]

        if current_segment:
            current_segment['text'] = test_extractor._select_best_text_from_variants(text_variants)
            merged_segments.append(current_segment)

        # æ­¥éª¤3ï¼šé—´éš™å¡«å……
        final_segments = test_extractor._fill_segment_gaps(merged_segments, filtered_frames, gap_time_threshold)

        return final_segments

    merged_segments = merge_segments_test(ocr_results=ocr_results)
    print(f"  âœ“ åˆå¹¶å®Œæˆ: {len(merged_segments)} ä¸ªæ®µè½\n")

    # 5. å¯¹æ¯”ç»“æœ
    print(f"[5/5] å¯¹æ¯”åˆå¹¶ç»“æœä¸æœŸæœ›ç»“æœ")
    stats = compare_segments(merged_segments, expected_segments)

    return {
        'raw_file': raw_srt,
        'expected_file': expected_srt,
        'raw_count': len(raw_segments),
        'expected_count': len(expected_segments),
        'merged_count': len(merged_segments),
        'stats': stats,
        'merged_segments': merged_segments
    }


def print_test_results(result: Dict):
    """æ‰“å°æµ‹è¯•ç»“æœ"""
    stats = result['stats']

    print(f"\n{'â”€'*80}")
    print(f"ğŸ“Š æµ‹è¯•ç»“æœç»Ÿè®¡")
    print(f"{'â”€'*80}")
    print(f"åŸå§‹æ®µè½æ•°: {result['raw_count']}")
    print(f"æœŸæœ›æ®µè½æ•°: {result['expected_count']}")
    print(f"åˆå¹¶æ®µè½æ•°: {result['merged_count']}")
    print(f"{'â”€'*80}")
    print(f"å®Œå…¨åŒ¹é…: {stats['exact_matches']} ä¸ª")
    print(f"éƒ¨åˆ†åŒ¹é…: {stats['partial_matches']} ä¸ª")
    print(f"å¤šä½™æ®µè½: {len(stats['extra'])} ä¸ª")
    print(f"ç¼ºå¤±æ®µè½: {len(stats['missing'])} ä¸ª")
    print(f"{'â”€'*80}")

    total_matches = stats['exact_matches'] + stats['partial_matches']
    if result['expected_count'] > 0:
        match_rate = (total_matches / result['expected_count']) * 100
        exact_rate = (stats['exact_matches'] / result['expected_count']) * 100
        print(f"åŒ¹é…ç‡: {match_rate:.1f}% ({total_matches}/{result['expected_count']})")
        print(f"å®Œå…¨åŒ¹é…ç‡: {exact_rate:.1f}% ({stats['exact_matches']}/{result['expected_count']})")

    if result['raw_count'] > 0:
        compression_rate = (1 - result['merged_count'] / result['raw_count']) * 100
        print(f"å‹ç¼©ç‡: {compression_rate:.1f}% ({result['raw_count']} â†’ {result['merged_count']})")

    # æ˜¾ç¤ºä¸åŒ¹é…çš„æ®µè½
    if stats['mismatches'] and len(stats['mismatches']) > 0:
        print(f"\n{'â”€'*80}")
        print(f"âš ï¸  éƒ¨åˆ†åŒ¹é…çš„æ®µè½ (å‰5ä¸ª):")
        print(f"{'â”€'*80}")
        for i, mismatch in enumerate(stats['mismatches'][:5], 1):
            merged = mismatch['merged']
            expected = mismatch['expected']
            similarity = mismatch['similarity']

            print(f"\n{i}. ç›¸ä¼¼åº¦: {similarity:.2f}")
            print(f"   åˆå¹¶ç»“æœ: [{format_time(merged['start_time'])} â†’ {format_time(merged['end_time'])}]")
            print(f"             \"{merged['text']}\"")
            print(f"   æœŸæœ›ç»“æœ: [{format_time(expected['start_time'])} â†’ {format_time(expected['end_time'])}]")
            print(f"             \"{expected['text']}\"")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print(f"\n{'='*80}")
    print(f"å­—å¹•åˆå¹¶å‡†ç¡®åº¦å®Œæ•´æµ‹è¯•")
    print(f"{'='*80}\n")

    # æµ‹è¯•æ–‡ä»¶å¯¹åˆ—è¡¨
    test_cases = [
        ('1_raw.srt', 'ghost_cut.srt'),
        ('2_raw.srt', 'ghost_cut_2.srt')
    ]

    results = []

    for raw_file, expected_file in test_cases:
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not Path(raw_file).exists():
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {raw_file}")
            continue
        if not Path(expected_file).exists():
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {expected_file}")
            continue

        # æ‰§è¡Œæµ‹è¯•
        result = test_single_file(raw_file, expected_file)
        results.append(result)

        # æ‰“å°ç»“æœ
        print_test_results(result)

        # ä¿å­˜åˆå¹¶ç»“æœ
        output_file = Path(raw_file).stem + '_merged_test.srt'
        with open(output_file, 'w', encoding='utf-8') as f:
            for idx, seg in enumerate(result['merged_segments'], 1):
                f.write(f"{idx}\n")
                f.write(f"{format_time(seg['start_time'])} --> {format_time(seg['end_time'])}\n")
                f.write(f"{seg['text']}\n")
                f.write("\n")

        print(f"\nğŸ’¾ åˆå¹¶ç»“æœå·²ä¿å­˜: {output_file}")

    # æ€»ç»“
    print(f"\n{'='*80}")
    print(f"ğŸ“ˆ å…¨éƒ¨æµ‹è¯•æ€»ç»“")
    print(f"{'='*80}")

    for i, result in enumerate(results, 1):
        stats = result['stats']
        total_matches = stats['exact_matches'] + stats['partial_matches']

        if result['expected_count'] > 0:
            match_rate = (total_matches / result['expected_count']) * 100
            exact_rate = (stats['exact_matches'] / result['expected_count']) * 100
        else:
            match_rate = 0
            exact_rate = 0

        print(f"\næµ‹è¯• {i}: {Path(result['raw_file']).stem}")
        print(f"  åŸå§‹æ®µè½: {result['raw_count']} â†’ åˆå¹¶æ®µè½: {result['merged_count']}")
        print(f"  åŒ¹é…ç‡: {match_rate:.1f}%  |  å®Œå…¨åŒ¹é…ç‡: {exact_rate:.1f}%")

        if match_rate >= 95:
            status = "âœ… ä¼˜ç§€"
        elif match_rate >= 85:
            status = "âœ“ è‰¯å¥½"
        elif match_rate >= 70:
            status = "âš ï¸  ä¸€èˆ¬"
        else:
            status = "âŒ éœ€æ”¹è¿›"

        print(f"  è¯„ä»·: {status}")

    print(f"\n{'='*80}")
    print(f"æµ‹è¯•å®Œæˆï¼")
    print(f"{'='*80}\n")


if __name__ == "__main__":
    main()
